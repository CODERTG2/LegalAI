{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Court Opinions Knowledge Graph (GLiNER)\n",
                "\n",
                "This notebook builds a knowledge graph from **Court Opinions** (e.g., SCOTUS) using **GLiNER**.\n",
                "It is part of the Universal Legal Knowledge Graph prototype."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install gliner networkx matplotlib tqdm -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import networkx as nx\n",
                "import matplotlib.pyplot as plt\n",
                "from gliner import GLiNER\n",
                "from tqdm import tqdm\n",
                "import os"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data\n",
                "Loading `opinions.json` or `opinion_chunks.json`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load opinions data\n",
                "files = ['opinions.json', 'opinion_chunks.json', 'opinions_full.json']\n",
                "target_file = None\n",
                "\n",
                "for f in files:\n",
                "    if os.path.exists(f):\n",
                "        target_file = f\n",
                "        break\n",
                "\n",
                "if not target_file:\n",
                "    print(\"Warning: No data file found. Using dummy data.\")\n",
                "    data = [\n",
                "        {\"text\": \"Justice Roberts delivered the opinion of the Court. In the case of Roe v. Wade, 410 U.S. 113 (1973), the Court held...\"},\n",
                "        {\"text\": \"Petitioner John Doe argues that the Agency violated the Administrative Procedure Act.\"}\n",
                "    ]\n",
                "else:\n",
                "    print(f\"Loading data from {target_file}...\")\n",
                "    with open(target_file, 'r') as f:\n",
                "        raw_data = json.load(f)\n",
                "    \n",
                "    data = []\n",
                "    if isinstance(raw_data, list):\n",
                "        # Limit for prototype speed\n",
                "        limit = 50\n",
                "        for item in raw_data[:limit]: \n",
                "            text = \"\"\n",
                "            # Try various common keys\n",
                "            if isinstance(item, str):\n",
                "                text = item\n",
                "            elif isinstance(item, dict):\n",
                "                if 'text' in item: text = item['text']\n",
                "                elif 'content' in item: text = item['content']\n",
                "                elif 'body' in item: text = item['body']\n",
                "                elif 'summary' in item: text = item['summary']\n",
                "                elif 'chunk_text' in item:\n",
                "                     if isinstance(item['chunk_text'], dict):\n",
                "                         text = item['chunk_text'].get('text', '')\n",
                "                     else:\n",
                "                         text = str(item['chunk_text'])\n",
                "            \n",
                "            if text:\n",
                "                data.append({'text': text})\n",
                "    else:\n",
                "        print(\"Unknown JSON structure\")\n",
                "        data = []\n",
                "        \n",
                "    print(f\"Loaded {len(data)} items.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Initialize GLiNER\n",
                "Using the Labels specific to Case Law."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")\n",
                "\n",
                "labels = [\n",
                "    # People & Roles\n",
                "    \"Judge\", \"Justice\", \"Petitioner\", \"Respondent\", \"Plaintiff\", \"Defendant\", \"Attorney\",\n",
                "    \n",
                "    # Institutions\n",
                "    \"Court\", \"Government Agency\", \"Organization\", \"Committee\",\n",
                "    \n",
                "    # Legal Docs & Concepts\n",
                "    \"Case Citation\", \"Statute\", \"Constitution\", \"Amendment\", \"Precedent\", \"Doctrine\",\n",
                "    \n",
                "    # Context\n",
                "    \"Date\", \"Location\", \"Topic\"\n",
                "]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Build the Graph"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "G = nx.Graph()\n",
                "\n",
                "for i, item in enumerate(tqdm(data)):\n",
                "    text = item.get('text', '')\n",
                "    if not text or len(text) < 50: continue\n",
                "    \n",
                "    # Create Chunk Node\n",
                "    chunk_id = f\"opinion_chunk_{i}\"\n",
                "    G.add_node(chunk_id, type=\"Chunk\", text=text[:50]+\"...\")\n",
                "    \n",
                "    # Extract Entities\n",
                "    try:\n",
                "        entities = model.predict_entities(text, labels)\n",
                "    except Exception as e:\n",
                "        print(f\"Error processing chunk {i}: {e}\")\n",
                "        continue\n",
                "    \n",
                "    entity_names = []\n",
                "    for entity in entities:\n",
                "        label = entity['label']\n",
                "        name = entity['text'].strip()\n",
                "        \n",
                "        # Add Entity Node\n",
                "        G.add_node(name, type=label)\n",
                "        \n",
                "        # Edge: Chunk -> Entity\n",
                "        G.add_edge(chunk_id, name, relation=\"MENTIONS\")\n",
                "        \n",
                "        entity_names.append(name)\n",
                "    \n",
                "    # Edge: Entity <-> Entity (Co-occurrence)\n",
                "    import itertools\n",
                "    for e1, e2 in itertools.combinations(entity_names, 2):\n",
                "        if not G.has_edge(e1, e2):\n",
                "            G.add_edge(e1, e2, relation=\"CO_OCCURS\", weight=1)\n",
                "        else:\n",
                "            G[e1][e2]['weight'] += 1\n",
                "\n",
                "print(f\"Graph constructed: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 12))\n",
                "\n",
                "# Filter out Chunk nodes for cleaner visualization\n",
                "entity_nodes = [n for n, attr in G.nodes(data=True) if attr['type'] != 'Chunk']\n",
                "subgraph = G.subgraph(entity_nodes)\n",
                "\n",
                "if len(subgraph.nodes()) > 0:\n",
                "    pos = nx.spring_layout(subgraph, k=0.15, iterations=20)\n",
                "    nx.draw_networkx_nodes(subgraph, pos, node_size=100, node_color=\"salmon\", alpha=0.7)\n",
                "    nx.draw_networkx_edges(subgraph, pos, alpha=0.2)\n",
                "    \n",
                "    final_labels = {}\n",
                "    degrees = dict(subgraph.degree())\n",
                "    top_nodes = sorted(degrees, key=degrees.get, reverse=True)[:20]\n",
                "    for node in top_nodes:\n",
                "        final_labels[node] = node\n",
                "        \n",
                "    nx.draw_networkx_labels(subgraph, pos, labels=final_labels, font_size=8, font_color=\"darkred\")\n",
                "    \n",
                "    plt.title(\"Court Opinions Entity Graph\")\n",
                "    plt.axis('off')\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"Not enough entity nodes to visualize.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nx.write_gexf(G, \"opinions_knowledge_graph.gexf\")\n",
                "print(\"Graph saved to opinions_knowledge_graph.gexf\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
