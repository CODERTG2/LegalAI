{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import re\n",
                "import os"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "load-data",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 218 orders.\n"
                    ]
                }
            ],
            "source": [
                "# Load extracted orders\n",
                "input_file = \"orders.json\"\n",
                "if not os.path.exists(input_file):\n",
                "    print(f\"Error: {input_file} not found. Please run orders.ipynb first.\")\n",
                "else:\n",
                "    with open(input_file, 'r', encoding='utf-8') as f:\n",
                "        orders = json.load(f)\n",
                "    print(f\"Loaded {len(orders)} orders.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "chunk-logic",
            "metadata": {},
            "outputs": [],
            "source": [
                "def chunk_order_text(text):\n",
                "    \"\"\"\n",
                "    Splits text by 'Section X.' or 'Sec. X.' headers.\n",
                "    Returns a list of dictionaries: [{'label': 'Section 1', 'text': '...'}]\n",
                "    \"\"\"\n",
                "    if not text:\n",
                "        return []\n",
                "    \n",
                "    # Regex to find headers like \"Section 1.\" or \"Sec. 1.\"\n",
                "    # Captures the header itself to use as a label\n",
                "    # Updated to handle newlines/whitespace before the final period (e.g. \"Section 1\\n\\n.\")\n",
                "    pattern = r\"((?:Section|Sec\\.)\\s+\\d+\\s*\\.)\"\n",
                "    \n",
                "    # Split by the pattern. capture=True keeps the separator (the header)\n",
                "    parts = re.split(pattern, text)\n",
                "    \n",
                "    chunks = []\n",
                "    current_label = \"Preamble\" # Text before first section\n",
                "    current_text = \"\"\n",
                "    \n",
                "    # parts[0] is text before first match (Preamble if exists)\n",
                "    if parts[0].strip():\n",
                "        chunks.append({'label': 'Preamble', 'text': parts[0].strip()})\n",
                "        \n",
                "    # Loop through the rest: header, text, header, text...\n",
                "    # Because regex capture group is used, parts list looks like: [preamble, Header1, Body1, Header2, Body2...]\n",
                "    for i in range(1, len(parts), 2):\n",
                "        header = parts[i].strip()\n",
                "        body = parts[i+1].strip() if i+1 < len(parts) else \"\"\n",
                "        \n",
                "        # Clean up body text (remove excessive newlines if needed, though usually fine)\n",
                "        body = re.sub(r'\\n+', ' ', body)\n",
                "        \n",
                "        chunks.append({\n",
                "            'label': header,\n",
                "            'text': (header + \" \" + body).strip() # Include header in text for context\n",
                "        })\n",
                "        \n",
                "    return chunks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "process-orders",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Chunking orders...\n",
                        "Created 1471 chunks from 218 orders.\n"
                    ]
                }
            ],
            "source": [
                "all_chunks = []\n",
                "\n",
                "print(\"Chunking orders...\")\n",
                "for order in orders:\n",
                "    text = order.get('full_text', '')\n",
                "    extracted_chunks = chunk_order_text(text)\n",
                "    \n",
                "    for c in extracted_chunks:\n",
                "        # Create a new record with same metadata + chunk info\n",
                "        chunk_record = order.copy()\n",
                "        chunk_record['chunk_text'] = c\n",
                "        \n",
                "        # Remove full_text to save space if desired, but user asked to \"keep all metadata\"\n",
                "        # The prompt said \"have each chunk have the same metadata as the og executive order\"\n",
                "        # Usually 'full_text' is metadata, but redundant here. I'll keep it to be safe or remove if too large.\n",
                "        # Let's remove 'full_text' from the chunk object to avoid massive duplication, \n",
                "        # as 'chunk_text' contains the relevant part.\n",
                "        if 'full_text' in chunk_record:\n",
                "            del chunk_record['full_text']\n",
                "            \n",
                "        all_chunks.append(chunk_record)\n",
                "        \n",
                "print(f\"Created {len(all_chunks)} chunks from {len(orders)} orders.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "save-chunks",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved to order_chunks.json\n"
                    ]
                }
            ],
            "source": [
                "output_file = \"order_chunks.json\"\n",
                "with open(output_file, 'w', encoding='utf-8') as f:\n",
                "    json.dump(all_chunks, f, ensure_ascii=False, indent=2)\n",
                "    \n",
                "print(f\"Saved to {output_file}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "verify-chunk",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Sample chunk:\n",
                        "{\n",
                        "  \"citation\": \"90 FR 43895\",\n",
                        "  \"document_number\": \" 2025-17509\",\n",
                        "  \"start_page\": \"43897\",\n",
                        "  \"url\": \"https://www.federalregister.gov/documents/2025/09/10/2025-17509/strengthening-efforts-to-protect-us-nationals-from-wrongful-detention-abroad\",\n",
                        "  \"pdf_url\": \"https://www.govinfo.gov/content/pkg/FR-2025-09-10/pdf/2025-17509.pdf\",\n",
                        "  \"doc_type\": \"Presidential Document\",\n",
                        "  \"doc_subtype\": \"Executive Order\",\n",
                        "  \"publication_date\": \"09/10/2025\",\n",
                        "  \"signing_date\": \"2025-09-05\",\n",
                        "  \"fr_page\": \"43895\",\n",
                        "  \"title\": \"Strengthening Efforts To Protect U.S. Nationals From Wrongful Detention Abroad\",\n",
                        "  \"notes\": \"See: EO 11295, August 5, 1966\",\n",
                        "  \"order_number\": \"14348\",\n",
                        "  \"internal_id\": NaN,\n",
                        "  \"chunk_text\": {\n",
                        "    \"label\": \"Section 1\\n\\n.\",\n",
                        "    \"text\": \"Section 1\\n\\n. Purpose. The United States must strengthen efforts to protect U.S. nationals from wrongful detention abroad. The United States Government is committed to using every tool available to curb this coercive tactic used by foreign adversaries and must hold such adversaries to account. No American should fear being taken as a political pawn by rogue states. Wrongful detentions are an affront to the rule of law and aim to undermine our leadership on the world stage. The United States will not tolerate these attacks on our sovereignty and U.S. nationals.\"\n",
                        "  }\n",
                        "}\n"
                    ]
                }
            ],
            "source": [
                "if all_chunks:\n",
                "    print(\"Sample chunk:\")\n",
                "    print(json.dumps(all_chunks[1], indent=2))\n",
                "else:\n",
                "    print(\"No chunks generated.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
